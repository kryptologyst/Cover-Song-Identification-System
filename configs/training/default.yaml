# @package training

_target_: src.train.trainer.Trainer

epochs: 100
learning_rate: 0.001
weight_decay: 1e-4
patience: 10
save_best: true
early_stopping: true
gradient_clip_val: 1.0

optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
  weight_decay: 1e-4

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  mode: "min"
  factor: 0.5
  patience: 5
  verbose: true

checkpoint:
  save_top_k: 3
  monitor: "val_loss"
  mode: "min"
  filename: "epoch_{epoch:02d}-val_loss_{val_loss:.4f}"
